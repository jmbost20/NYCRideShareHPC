---
title: "R Notebook"
output: html_notebook
---
# Group Members
Peter Harmer


# Github Repository
https://github.com/jmbost20/Stat405Project

# Data Source
https://www.kaggle.com/datasets/jeffsinsel/nyc-fhvhv-data

# Code Snippets

### Code for Wget Files

2 Shell Scripts for Reading Files
* Submit.sh
* getData.sh

### Code from getData.sh
#!/bin/bash

n=$SLURM_ARRAY_TASK_ID


numid=$((2018+$n))

for i in 01 02 03 04 05 06 07 08 09 10 11 12
do
#if ($i <= 9)
#then
#wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_$numid-0$i.parquet
#else
wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_$numid-$i.parquet
#fi
done

### Converting Parquet to CSV

```{r}
install.packages("arrow")

library(arrow)

```

```{r}
parquet_file <- "fhvhv_tripdata_2020-05.parquet"

df <- read_parquet(parquet_file)

csv_file <- "fhvhv.csv"

write.csv(df, file = csv_file, row.names = FALSE)

```

# Variables


## Statistical Methods

### Data Analysis:
* Creating graphs that focus on displaying differences in driver pay and performance for each ride-sharing service
* Creating graphs that display correlation between certain variables and driver pay

### Regression:
* Using linear and/or Polynomial regression to identify the variables that have the largest impact on driver pay
* Will implement regression lines into analysis graphs to show relationship between variables and driver pay


# Computational Steps 

* Data Collection- pull Data from Kaggle (wget)
* Data Cleaning- Convert all Parquet files to CSV (Create some metrics for data conversion to ensure that little to no data is lost)
* Potentially some Feature Engineering
* Questions- Create code to address questions
* Pick one question for proposal

